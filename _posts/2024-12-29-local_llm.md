---
title: 本地部署大语言模型 
author: "Zhao Zilong"
date: 2024-10-28
category: Linux
layout: post
---


## 首先部署后端

```bash
curl -fsSL https://ollama.com/install.sh | sh
ollama run llama3.2
```

## 然后部署前端

```bash
sudo apt install docker.io
sudo docker run -d -p 3210:3210 -e OLLAMA_PROXY_URL=http://host.docker.internal:11434/v1 lobehub/lobe-chat
```


